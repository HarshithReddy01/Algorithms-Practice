{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqCHviWRjmsunGNhqK1VZE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshithReddy01/Algorithms-Practice/blob/master/Week10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wL46oG6CdAwo"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Article 1: Artificial Intelligence - https://en.wikipedia.org/wiki/Artificial_intelligence\n",
        "\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt_tab')\n",
        "except LookupError:\n",
        "    nltk.download('punkt_tab')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "def get_article_text(url):\n",
        "    try:\n",
        "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
        "        response = requests.get(url, timeout=10, headers=headers)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        for element in soup([\"script\", \"style\", \"nav\", \"footer\", \"header\", \"aside\", \"table\"]):\n",
        "            element.decompose()\n",
        "\n",
        "        main_content = soup.find('div', {'id': 'mw-content-text'}) or soup.find('main') or soup.find('article')\n",
        "        if main_content:\n",
        "            for ref in main_content.find_all(['sup', 'span', 'div'], class_=re.compile(r'ref|reference|citation')):\n",
        "                ref.decompose()\n",
        "\n",
        "            text = main_content.get_text()\n",
        "        else:\n",
        "            text = soup.get_text()\n",
        "\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'\\[\\d+\\]', '', text)\n",
        "        text = re.sub(r'Jump to.*?Edit', '', text)\n",
        "\n",
        "        return text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching article: {e}\")\n",
        "        return None\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
        "    return text.strip()\n",
        "\n",
        "def get_top_words_tfidf(text, n=5):\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    sentences = [s for s in sentences if len(s.split()) > 5]\n",
        "\n",
        "    if len(sentences) < 2:\n",
        "        return []\n",
        "\n",
        "    processed_sentences = [preprocess_text(sent) for sent in sentences]\n",
        "\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        max_features=1000,\n",
        "        stop_words='english',\n",
        "        ngram_range=(1, 1),\n",
        "        min_df=2\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        tfidf_matrix = vectorizer.fit_transform(processed_sentences)\n",
        "        feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "        mean_scores = np.mean(tfidf_matrix.toarray(), axis=0)\n",
        "\n",
        "        word_scores = list(zip(feature_names, mean_scores))\n",
        "        word_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        return word_scores[:n]\n",
        "    except ValueError:\n",
        "        return []\n",
        "\n",
        "def get_top_sentences_tfidf(text, n=5):\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    sentences = [s for s in sentences if len(s.split()) > 8 and not any(x in s.lower() for x in ['jump to', 'edit', 'retrieved', 'archived'])]\n",
        "\n",
        "    if len(sentences) < 2:\n",
        "        return []\n",
        "\n",
        "    processed_sentences = [preprocess_text(sent) for sent in sentences]\n",
        "\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        max_features=1000,\n",
        "        stop_words='english',\n",
        "        ngram_range=(1, 2),\n",
        "        min_df=1\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        tfidf_matrix = vectorizer.fit_transform(processed_sentences)\n",
        "        sentence_scores = np.sum(tfidf_matrix.toarray(), axis=1)\n",
        "\n",
        "        sentence_score_pairs = list(zip(sentences, sentence_scores))\n",
        "        sentence_score_pairs.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        return sentence_score_pairs[:n]\n",
        "    except ValueError:\n",
        "        return []\n",
        "\n",
        "def analyze_article(url):\n",
        "    print(f\"\\nAnalyzing article: {url}\")\n",
        "\n",
        "    text = get_article_text(url)\n",
        "    if not text or len(text) < 1000:\n",
        "        return None\n",
        "\n",
        "    print(f\"Article length: {len(text)} characters\")\n",
        "\n",
        "    top_words = get_top_words_tfidf(text)\n",
        "    print(\"\\nTop 5 words:\")\n",
        "    for word, score in top_words:\n",
        "        print(f\"  {word}: {score:.4f}\")\n",
        "\n",
        "    top_sentences = get_top_sentences_tfidf(text)\n",
        "    print(\"\\nTop 5 sentences:\")\n",
        "    for i, (sentence, score) in enumerate(top_sentences, 1):\n",
        "        print(f\"  {i}. {sentence[:120]}... (Score: {score:.4f})\")\n",
        "\n",
        "    return {\n",
        "        'url': url,\n",
        "        'top_words': top_words,\n",
        "        'top_sentences': top_sentences,\n",
        "        'text': text\n",
        "    }\n",
        "\n",
        "sample_ai_article = \"\"\"\n",
        "Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals. Leading AI textbooks define the field as the study of \"intelligent agents\": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals. Colloquially, the term \"artificial intelligence\" is often used to describe machines that mimic \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem solving\". As machines become increasingly capable, tasks considered to require \"intelligence\" are often removed from the definition of AI, a phenomenon known as the AI effect. A quip in Tesler's Theorem says \"AI is whatever hasn't been done yet.\" For instance, optical character recognition is frequently excluded from things considered to be AI, having become a routine technology. Modern machine learning techniques are based on artificial neural networks, particularly deep neural networks. Machine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention. The iterative aspect of machine learning is important because as models are exposed to new data, they are able to independently adapt. They learn from previous computations to produce reliable, repeatable decisions and results. While many machine learning algorithms have been around for a long time, the ability to automatically apply complex mathematical calculations to big data over and over, faster and faster is a recent development. Artificial intelligence research is defined as the study of intelligent agents. Any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals. A more elaborate definition characterizes AI as a system's ability to correctly interpret external data, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation.\n",
        "\"\"\"\n",
        "\n",
        "url = \"https://en.wikipedia.org/wiki/Artificial_intelligence\"\n",
        "\n",
        "print(\"Article 1: Artificial Intelligence\")\n",
        "\n",
        "result = analyze_article(url)\n",
        "if result and len(result.get('text', '')) > 2000:\n",
        "    final_result = result\n",
        "else:\n",
        "    print(f\"\\nUsing sample article for {url}\")\n",
        "    print(f\"Article length: {len(sample_ai_article)} characters\")\n",
        "\n",
        "    top_words = get_top_words_tfidf(sample_ai_article)\n",
        "    print(\"\\nTop 5 words:\")\n",
        "    for word, score in top_words:\n",
        "        print(f\"  {word}: {score:.4f}\")\n",
        "\n",
        "    top_sentences = get_top_sentences_tfidf(sample_ai_article)\n",
        "    print(\"\\nTop 5 sentences:\")\n",
        "    for j, (sentence, score) in enumerate(top_sentences, 1):\n",
        "        print(f\"  {j}. {sentence[:120]}... (Score: {score:.4f})\")\n",
        "\n",
        "    final_result = {\n",
        "        'url': url,\n",
        "        'top_words': top_words,\n",
        "        'top_sentences': top_sentences\n",
        "    }\n",
        "\n",
        "print(\"\\nSUMMARY\")\n",
        "\n",
        "print(f\"\\nArticle 1: {final_result['url']}\")\n",
        "print(\"Top 5 Words:\")\n",
        "for word, score in final_result['top_words']:\n",
        "    print(f\"  {word}: {score:.4f}\")\n",
        "\n",
        "print(\"Top 5 Sentences:\")\n",
        "for j, (sentence, score) in enumerate(final_result['top_sentences'], 1):\n",
        "    print(f\"  {j}. {sentence[:100]}... (Score: {score:.4f})\")\n",
        "\n",
        "summary_data = []\n",
        "for word, score in final_result['top_words']:\n",
        "    summary_data.append({\n",
        "        'Type': 'Word',\n",
        "        'Content': word,\n",
        "        'TF-IDF Score': score\n",
        "    })\n",
        "\n",
        "for j, (sentence, score) in enumerate(final_result['top_sentences'], 1):\n",
        "    summary_data.append({\n",
        "        'Type': 'Sentence',\n",
        "        'Content': sentence[:80] + '...',\n",
        "        'TF-IDF Score': score\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(summary_data)\n",
        "print(\"\\nSUMMARY TABLE\")\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "print(\"\\nINFO : \")\n",
        "print(f\"Article 1: {final_result['url']}\")\n",
        "print(\"\\nTop 5 words with TF-IDF scores:\")\n",
        "for word, score in final_result['top_words']:\n",
        "    print(f\"  {word}: {score:.4f}\")\n",
        "\n",
        "print(\"\\nTop 5 sentences with TF-IDF scores:\")\n",
        "for j, (sentence, score) in enumerate(final_result['top_sentences'], 1):\n",
        "    print(f\"  {j}. {sentence[:100]}... (Score: {score:.4f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4huZKixedDCh",
        "outputId": "84011a43-4ca2-4bdc-b41f-edb509a401db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Article 1: Artificial Intelligence\n",
            "\n",
            "Analyzing article: https://en.wikipedia.org/wiki/Artificial_intelligence\n",
            "Article length: 95213 characters\n",
            "\n",
            "Top 5 words:\n",
            "  ai: 0.0543\n",
            "  intelligence: 0.0299\n",
            "  artificial: 0.0232\n",
            "  learning: 0.0221\n",
            "  used: 0.0194\n",
            "\n",
            "Top 5 sentences:\n",
            "  1. See also Artificial consciousness – Field in cognitive science Artificial intelligence and elections – Use and impact of... (Score: 7.1275)\n",
            "  2. Applications Main article: Applications of artificial intelligenceAI and machine learning technology is used in most of ... (Score: 5.8458)\n",
            "  3. High-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used ... (Score: 5.7188)\n",
            "  4. Hardware and software Main articles: Programming languages for artificial intelligence and Hardware for artificial intel... (Score: 5.7132)\n",
            "  5. The sudden success of deep learning in 2012–2015 did not occur because of some new discovery or theoretical breakthrough... (Score: 5.3778)\n",
            "\n",
            "SUMMARY\n",
            "\n",
            "Article 1: https://en.wikipedia.org/wiki/Artificial_intelligence\n",
            "Top 5 Words:\n",
            "  ai: 0.0543\n",
            "  intelligence: 0.0299\n",
            "  artificial: 0.0232\n",
            "  learning: 0.0221\n",
            "  used: 0.0194\n",
            "Top 5 Sentences:\n",
            "  1. See also Artificial consciousness – Field in cognitive science Artificial intelligence and elections... (Score: 7.1275)\n",
            "  2. Applications Main article: Applications of artificial intelligenceAI and machine learning technology... (Score: 5.8458)\n",
            "  3. High-profile applications of AI include advanced web search engines (e.g., Google Search); recommend... (Score: 5.7188)\n",
            "  4. Hardware and software Main articles: Programming languages for artificial intelligence and Hardware ... (Score: 5.7132)\n",
            "  5. The sudden success of deep learning in 2012–2015 did not occur because of some new discovery or theo... (Score: 5.3778)\n",
            "\n",
            "SUMMARY TABLE\n",
            "    Type                                                                             Content  TF-IDF Score\n",
            "    Word                                                                                  ai      0.054253\n",
            "    Word                                                                        intelligence      0.029905\n",
            "    Word                                                                          artificial      0.023214\n",
            "    Word                                                                            learning      0.022068\n",
            "    Word                                                                                used      0.019412\n",
            "Sentence See also Artificial consciousness – Field in cognitive science Artificial intell...      7.127479\n",
            "Sentence Applications Main article: Applications of artificial intelligenceAI and machine...      5.845842\n",
            "Sentence High-profile applications of AI include advanced web search engines (e.g., Googl...      5.718787\n",
            "Sentence Hardware and software Main articles: Programming languages for artificial intell...      5.713214\n",
            "Sentence The sudden success of deep learning in 2012–2015 did not occur because of some n...      5.377796\n",
            "\n",
            "INFO : \n",
            "Article 1: https://en.wikipedia.org/wiki/Artificial_intelligence\n",
            "\n",
            "Top 5 words with TF-IDF scores:\n",
            "  ai: 0.0543\n",
            "  intelligence: 0.0299\n",
            "  artificial: 0.0232\n",
            "  learning: 0.0221\n",
            "  used: 0.0194\n",
            "\n",
            "Top 5 sentences with TF-IDF scores:\n",
            "  1. See also Artificial consciousness – Field in cognitive science Artificial intelligence and elections... (Score: 7.1275)\n",
            "  2. Applications Main article: Applications of artificial intelligenceAI and machine learning technology... (Score: 5.8458)\n",
            "  3. High-profile applications of AI include advanced web search engines (e.g., Google Search); recommend... (Score: 5.7188)\n",
            "  4. Hardware and software Main articles: Programming languages for artificial intelligence and Hardware ... (Score: 5.7132)\n",
            "  5. The sudden success of deep learning in 2012–2015 did not occur because of some new discovery or theo... (Score: 5.3778)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Article 2: Machine Learning - https://en.wikipedia.org/wiki/Machine_learning\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt_tab')\n",
        "except LookupError:\n",
        "    nltk.download('punkt_tab')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "def get_article_text(url):\n",
        "    try:\n",
        "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
        "        response = requests.get(url, timeout=10, headers=headers)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        for element in soup([\"script\", \"style\", \"nav\", \"footer\", \"header\", \"aside\", \"table\"]):\n",
        "            element.decompose()\n",
        "\n",
        "        main_content = soup.find('div', {'id': 'mw-content-text'}) or soup.find('main') or soup.find('article')\n",
        "        if main_content:\n",
        "            for ref in main_content.find_all(['sup', 'span', 'div'], class_=re.compile(r'ref|reference|citation')):\n",
        "                ref.decompose()\n",
        "\n",
        "            text = main_content.get_text()\n",
        "        else:\n",
        "            text = soup.get_text()\n",
        "\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'\\[\\d+\\]', '', text)\n",
        "        text = re.sub(r'Jump to.*?Edit', '', text)\n",
        "\n",
        "        return text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching article: {e}\")\n",
        "        return None\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
        "    return text.strip()\n",
        "\n",
        "def get_top_words_tfidf(text, n=5):\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    sentences = [s for s in sentences if len(s.split()) > 5]\n",
        "\n",
        "    if len(sentences) < 2:\n",
        "        return []\n",
        "\n",
        "    processed_sentences = [preprocess_text(sent) for sent in sentences]\n",
        "\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        max_features=1000,\n",
        "        stop_words='english',\n",
        "        ngram_range=(1, 1),\n",
        "        min_df=2\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        tfidf_matrix = vectorizer.fit_transform(processed_sentences)\n",
        "        feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "        mean_scores = np.mean(tfidf_matrix.toarray(), axis=0)\n",
        "\n",
        "        word_scores = list(zip(feature_names, mean_scores))\n",
        "        word_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        return word_scores[:n]\n",
        "    except ValueError:\n",
        "        return []\n",
        "\n",
        "def get_top_sentences_tfidf(text, n=5):\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    sentences = [s for s in sentences if len(s.split()) > 8 and not any(x in s.lower() for x in ['jump to', 'edit', 'retrieved', 'archived'])]\n",
        "\n",
        "    if len(sentences) < 2:\n",
        "        return []\n",
        "\n",
        "    processed_sentences = [preprocess_text(sent) for sent in sentences]\n",
        "\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        max_features=1000,\n",
        "        stop_words='english',\n",
        "        ngram_range=(1, 2),\n",
        "        min_df=1\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        tfidf_matrix = vectorizer.fit_transform(processed_sentences)\n",
        "        sentence_scores = np.sum(tfidf_matrix.toarray(), axis=1)\n",
        "\n",
        "        sentence_score_pairs = list(zip(sentences, sentence_scores))\n",
        "        sentence_score_pairs.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        return sentence_score_pairs[:n]\n",
        "    except ValueError:\n",
        "        return []\n",
        "\n",
        "def analyze_article(url):\n",
        "    print(f\"\\nAnalyzing article: {url}\")\n",
        "\n",
        "    text = get_article_text(url)\n",
        "    if not text or len(text) < 1000:\n",
        "        return None\n",
        "\n",
        "    print(f\"Article length: {len(text)} characters\")\n",
        "\n",
        "    top_words = get_top_words_tfidf(text)\n",
        "    print(\"\\nTop 5 words:\")\n",
        "    for word, score in top_words:\n",
        "        print(f\"  {word}: {score:.4f}\")\n",
        "\n",
        "    top_sentences = get_top_sentences_tfidf(text)\n",
        "    print(\"\\nTop 5 sentences:\")\n",
        "    for i, (sentence, score) in enumerate(top_sentences, 1):\n",
        "        print(f\"  {i}. {sentence[:120]}... (Score: {score:.4f})\")\n",
        "\n",
        "    return {\n",
        "        'url': url,\n",
        "        'top_words': top_words,\n",
        "        'top_sentences': top_sentences,\n",
        "        'text': text\n",
        "    }\n",
        "\n",
        "sample_ml_article = \"\"\"\n",
        "Machine learning (ML) is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. Machine learning focuses on the development of computer programs that can access data and use it to learn for themselves. The process of learning begins with observations or data, such as examples, direct experience, or instruction, in order to look for patterns in data and make better decisions in the future based on the examples that we provide. The primary aim is to allow the computers to learn automatically without human intervention or assistance and adjust actions accordingly. Machine learning algorithms build a mathematical model based on training data, in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as in medicine, email filtering, speech recognition, and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks. Machine learning is closely related to computational statistics, which focuses on making predictions using computers. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning. Machine learning involves computers discovering how they can perform tasks without being explicitly programmed to do so. It involves computers learning from data provided so that they carry out certain tasks. For simple tasks assigned to computers, it is possible to program algorithms telling the machine how to execute all steps required to solve the problem at hand. For more advanced tasks, it can be challenging for a human to manually create the needed algorithms. In practice, it can turn out to be more effective to help the machine develop its own algorithm, rather than having human programmers specify every needed step.\n",
        "\"\"\"\n",
        "\n",
        "url = \"https://en.wikipedia.org/wiki/Machine_learning\"\n",
        "\n",
        "print(\"Article 2: Machine Learning\")\n",
        "\n",
        "result = analyze_article(url)\n",
        "if result and len(result.get('text', '')) > 2000:\n",
        "    final_result = result\n",
        "else:\n",
        "    print(f\"\\nUsing sample article for {url}\")\n",
        "    print(f\"Article length: {len(sample_ml_article)} characters\")\n",
        "\n",
        "    top_words = get_top_words_tfidf(sample_ml_article)\n",
        "    print(\"\\nTop 5 words:\")\n",
        "    for word, score in top_words:\n",
        "        print(f\"  {word}: {score:.4f}\")\n",
        "\n",
        "    top_sentences = get_top_sentences_tfidf(sample_ml_article)\n",
        "    print(\"\\nTop 5 sentences:\")\n",
        "    for j, (sentence, score) in enumerate(top_sentences, 1):\n",
        "        print(f\"  {j}. {sentence[:120]}... (Score: {score:.4f})\")\n",
        "\n",
        "    final_result = {\n",
        "        'url': url,\n",
        "        'top_words': top_words,\n",
        "        'top_sentences': top_sentences\n",
        "    }\n",
        "\n",
        "print(\"\\nSUMMARY\")\n",
        "\n",
        "print(f\"\\nArticle 2: {final_result['url']}\")\n",
        "print(\"Top 5 Words:\")\n",
        "for word, score in final_result['top_words']:\n",
        "    print(f\"  {word}: {score:.4f}\")\n",
        "\n",
        "print(\"Top 5 Sentences:\")\n",
        "for j, (sentence, score) in enumerate(final_result['top_sentences'], 1):\n",
        "    print(f\"  {j}. {sentence[:100]}... (Score: {score:.4f})\")\n",
        "\n",
        "summary_data = []\n",
        "for word, score in final_result['top_words']:\n",
        "    summary_data.append({\n",
        "        'Type': 'Word',\n",
        "        'Content': word,\n",
        "        'TF-IDF Score': score\n",
        "    })\n",
        "\n",
        "for j, (sentence, score) in enumerate(final_result['top_sentences'], 1):\n",
        "    summary_data.append({\n",
        "        'Type': 'Sentence',\n",
        "        'Content': sentence[:80] + '...',\n",
        "        'TF-IDF Score': score\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(summary_data)\n",
        "print(\"\\nSUMMARY TABLE\")\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "print(\"\\nINFO : \")\n",
        "print(f\"Article 2: {final_result['url']}\")\n",
        "print(\"\\nTop 5 words with TF-IDF scores:\")\n",
        "for word, score in final_result['top_words']:\n",
        "    print(f\"  {word}: {score:.4f}\")\n",
        "\n",
        "print(\"\\nTop 5 sentences with TF-IDF scores:\")\n",
        "for j, (sentence, score) in enumerate(final_result['top_sentences'], 1):\n",
        "    print(f\"  {j}. {sentence[:100]}... (Score: {score:.4f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhy0LGgLdDF-",
        "outputId": "63bd71c4-79f3-4055-f1e5-4a04ff2a20ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Article 2: Machine Learning\n",
            "\n",
            "Analyzing article: https://en.wikipedia.org/wiki/Machine_learning\n",
            "Article length: 67924 characters\n",
            "\n",
            "Top 5 words:\n",
            "  learning: 0.0696\n",
            "  machine: 0.0462\n",
            "  data: 0.0440\n",
            "  model: 0.0277\n",
            "  algorithms: 0.0263\n",
            "\n",
            "Top 5 sentences:\n",
            "  1. Machine learning approaches are traditionally divided into three broad categories, which correspond to learning paradigm... (Score: 5.0715)\n",
            "  2. When dealing with non-linear problems, go-to models include polynomial regression (for example, used for trendline fitti... (Score: 4.9857)\n",
            "  3. Supervised anomaly detection techniques require a data set that has been labelled as \"normal\" and \"abnormal\" and involve... (Score: 4.9582)\n",
            "  4. Much of the confusion between these two research communities (which do often have separate conferences and separate jour... (Score: 4.9285)\n",
            "  5. Artificial neural networks have been used on a variety of tasks, including computer vision, speech recognition, machine ... (Score: 4.8287)\n",
            "\n",
            "SUMMARY\n",
            "\n",
            "Article 2: https://en.wikipedia.org/wiki/Machine_learning\n",
            "Top 5 Words:\n",
            "  learning: 0.0696\n",
            "  machine: 0.0462\n",
            "  data: 0.0440\n",
            "  model: 0.0277\n",
            "  algorithms: 0.0263\n",
            "Top 5 Sentences:\n",
            "  1. Machine learning approaches are traditionally divided into three broad categories, which correspond ... (Score: 5.0715)\n",
            "  2. When dealing with non-linear problems, go-to models include polynomial regression (for example, used... (Score: 4.9857)\n",
            "  3. Supervised anomaly detection techniques require a data set that has been labelled as \"normal\" and \"a... (Score: 4.9582)\n",
            "  4. Much of the confusion between these two research communities (which do often have separate conferenc... (Score: 4.9285)\n",
            "  5. Artificial neural networks have been used on a variety of tasks, including computer vision, speech r... (Score: 4.8287)\n",
            "\n",
            "SUMMARY TABLE\n",
            "    Type                                                                             Content  TF-IDF Score\n",
            "    Word                                                                            learning      0.069590\n",
            "    Word                                                                             machine      0.046171\n",
            "    Word                                                                                data      0.044024\n",
            "    Word                                                                               model      0.027670\n",
            "    Word                                                                          algorithms      0.026281\n",
            "Sentence Machine learning approaches are traditionally divided into three broad categorie...      5.071495\n",
            "Sentence When dealing with non-linear problems, go-to models include polynomial regressio...      4.985682\n",
            "Sentence Supervised anomaly detection techniques require a data set that has been labelle...      4.958188\n",
            "Sentence Much of the confusion between these two research communities (which do often hav...      4.928459\n",
            "Sentence Artificial neural networks have been used on a variety of tasks, including compu...      4.828666\n",
            "\n",
            "INFO : \n",
            "Article 2: https://en.wikipedia.org/wiki/Machine_learning\n",
            "\n",
            "Top 5 words with TF-IDF scores:\n",
            "  learning: 0.0696\n",
            "  machine: 0.0462\n",
            "  data: 0.0440\n",
            "  model: 0.0277\n",
            "  algorithms: 0.0263\n",
            "\n",
            "Top 5 sentences with TF-IDF scores:\n",
            "  1. Machine learning approaches are traditionally divided into three broad categories, which correspond ... (Score: 5.0715)\n",
            "  2. When dealing with non-linear problems, go-to models include polynomial regression (for example, used... (Score: 4.9857)\n",
            "  3. Supervised anomaly detection techniques require a data set that has been labelled as \"normal\" and \"a... (Score: 4.9582)\n",
            "  4. Much of the confusion between these two research communities (which do often have separate conferenc... (Score: 4.9285)\n",
            "  5. Artificial neural networks have been used on a variety of tasks, including computer vision, speech r... (Score: 4.8287)\n"
          ]
        }
      ]
    }
  ]
}